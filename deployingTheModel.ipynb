{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import keras.backend as k\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r'E:\\tonyStark\\NeuralNetworks\\gesture\\best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"Trackbars\")    \n",
    "cv2.resizeWindow(\"Trackbars\", 640, 320)\n",
    "cv2.createTrackbar(\"hMin\", \"Trackbars\", 53, 179, empty)     \n",
    "cv2.createTrackbar(\"hMax\", \"Trackbars\", 140, 179, empty)\n",
    "cv2.createTrackbar(\"sMin\", \"Trackbars\", 57, 255, empty)\n",
    "cv2.createTrackbar(\"sMax\", \"Trackbars\", 192, 255, empty)\n",
    "cv2.createTrackbar(\"vMin\", \"Trackbars\", 67, 255, empty)\n",
    "cv2.createTrackbar(\"vMax\", \"Trackbars\", 166, 255, empty)\n",
    "\n",
    "while True:\n",
    "    succ, img = cap.read()\n",
    "    cv2.rectangle(img, (300,100), (500,300), (255,255,255), 1)\n",
    "    \n",
    "    hMin = cv2.getTrackbarPos(\"hMin\", \"Trackbars\")      \n",
    "    hMax = cv2.getTrackbarPos(\"hMax\", \"Trackbars\")\n",
    "    sMin = cv2.getTrackbarPos(\"sMin\", \"Trackbars\")\n",
    "    sMax = cv2.getTrackbarPos(\"sMax\", \"Trackbars\")\n",
    "    vMin = cv2.getTrackbarPos(\"vMin\", \"Trackbars\")\n",
    "    vMax = cv2.getTrackbarPos(\"vMax\", \"Trackbars\")\n",
    "    \n",
    "    lowerArr = np.array([hMin, sMin, vMin])\n",
    "    upperArr = np.array([hMax, sMax, vMax])\n",
    "    mask = cv2.inRange(img, lowerArr, upperArr)\n",
    "    \n",
    "    cv2.rectangle(mask, (300,100), (500,300), (255,255,255), 1)\n",
    "    \n",
    "    cropped = mask[100:300, 300:500]\n",
    "    cropped = cv2.cvtColor(cropped,cv2.COLOR_GRAY2RGB)\n",
    "    cropped = cv2.resize(cropped, (224, 224))\n",
    "    \n",
    "    cropped = image.img_to_array(cropped)\n",
    "    cropped = np.expand_dims(cropped, axis=0)\n",
    "    cropped = keras.applications.mobilenet.preprocess_input(cropped)\n",
    "    prediction = model.predict(cropped)\n",
    "    fist = prediction[0][0]\n",
    "    palm = prediction[0][1]\n",
    "    peace = prediction[0][2]\n",
    "    \n",
    "    cv2.line(img, (20,20), (int(fist*500),20), (255,255,255), 8)\n",
    "    cv2.line(img, (20,40), (int(palm*500),40), (255,255,255), 8)\n",
    "    cv2.line(img, (20,60), (int(peace*500),60), (255,255,255), 8)\n",
    "    \n",
    "    fistP = int(fist*100)\n",
    "    palmP = int(palm*100)\n",
    "    peaceP = int(peace*100)\n",
    "    \n",
    "    cv2.putText(img, str(fistP)+\"%\", (450,20), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,0,255), 1)\n",
    "    cv2.putText(img, str(palmP)+\"%\", (450,40), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,0,255), 1)\n",
    "    cv2.putText(img, str(peaceP)+\"%\", (450,60), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,0,255), 1)\n",
    "    \n",
    "    cv2.putText(img, \"fist\", (485,20), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,0,255), 1)\n",
    "    cv2.putText(img, \"palm\", (485,40), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,0,255), 1)\n",
    "    cv2.putText(img, \"peace\", (485,60), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,0,255), 1)\n",
    "    \n",
    "    arr = [fist, palm, peace]\n",
    "\n",
    "    ind = arr.index(max(arr))\n",
    "    \n",
    "    if ind==1:\n",
    "        cv2.putText(img, \"palm\", (50,100), cv2.FONT_HERSHEY_COMPLEX, 1, (144,0,255), 1)\n",
    "    elif ind==2:\n",
    "        cv2.putText(img, \"peace\", (50,100), cv2.FONT_HERSHEY_COMPLEX, 1, (144,0,255), 1)\n",
    "    else:\n",
    "        cv2.putText(img, \"fist\", (50,100), cv2.FONT_HERSHEY_COMPLEX, 1, (144,0,255), 1)    \n",
    "        \n",
    "    cv2.imshow('1', img)\n",
    "    cv2.imshow('2', mask)    \n",
    "        \n",
    "    inp = cv2.waitKey(1) & 0xFF\n",
    "    if inp==ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
